package com.yourorg.telemedicine.ai.service;

import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.*;
import org.springframework.stereotype.Service;
import org.springframework.web.client.RestTemplate;

@Service
public class LlamaServiceImpl implements LlamaService {

    @Value("${llama.api.key}")
    private String apiKey;

    private final RestTemplate restTemplate = new RestTemplate();

    @Override
    public String ask(String prompt) {

        String url = "https://api.groq.com/openai/v1/chat/completions";

        String body = """
        		{
        		  "model": "llama3-8b-8192",
        		  "messages": [{
        		     "role": "user",
        		     "content": "%s"
        		  }]
        		}
        		""".formatted(prompt);


        HttpHeaders headers = new HttpHeaders();
        headers.setContentType(MediaType.APPLICATION_JSON);
        headers.setBearerAuth(apiKey);

        HttpEntity<String> entity = new HttpEntity<>(body, headers);

        ResponseEntity<String> response =
                restTemplate.postForEntity(url, entity, String.class);

        return extractText(response.getBody());
    }

    // simple extraction
    private String extractText(String json) {
        int idx = json.indexOf("\"content\":\"");
        if (idx == -1) return "AI response unavailable";
        int start = idx + 11;
        int end = json.indexOf("\"", start);
        return json.substring(start, end);
    }
}
